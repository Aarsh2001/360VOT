# 360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking
Huajian Huang, Yinzhe Xu, Yingshu Chen and Sai-Kit Yeungs <br>
| [Homepage]() | [Paper]() |
[Video]() | [Benchmark Dataset]() |

![image](asset/teaser.jpg "360VOT")

## Introduction
The proposed 360VOT is the first benchmark dataset for omnidirectional visual object tracking. We explore the new representations for visual object
tracking and provide four types of unbiased ground truth, including <span style="color:(48, 188, 227)">bounding box (BBox)</span>, <span style="color:(121, 224, 167)">rotated bounding box (rBBox)</span>,<span style="color:(224, 161, 101)">bounding field-of-view (BFoV)</span>,<span style="color:(224, 107, 96)">rotated bounding field-of-view (rBFoV)</span>. We propose new metrics for omnidirectional tracking evaluation, which measure the dual success rate and angle precision on the sphere. By releasing 360VOT, we believe that the new dataset, representations, metrics, and benchmark can encourage more research and application of omnidirectional visual object tracking in both computer vision and robotics.

## Installation


## Usage

### 